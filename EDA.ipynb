{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76cd4c70-4c50-468c-9d39-786113e270fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: cols_with_missing_values = ['collision_type', 'authorities_contacted', 'property_damage', 'police_report_available']\n",
      "DEBUG: data columns = Index(['months_as_customer', 'policy_csl', 'policy_deductable',\n",
      "       'policy_annual_premium', 'umbrella_limit', 'insured_sex',\n",
      "       'insured_education_level', 'insured_occupation', 'insured_relationship',\n",
      "       'capital-gains', 'capital-loss', 'incident_type', 'collision_type',\n",
      "       'incident_severity', 'authorities_contacted',\n",
      "       'incident_hour_of_the_day', 'number_of_vehicles_involved',\n",
      "       'property_damage', 'bodily_injuries', 'witnesses',\n",
      "       'police_report_available', 'injury_claim', 'property_claim',\n",
      "       'vehicle_claim'],\n",
      "      dtype='object')\n",
      "DEBUG: data shape = (1000, 24)\n",
      "DEBUG: imputing column collision_type type: <class 'str'>\n",
      "DEBUG: imputing column authorities_contacted type: <class 'str'>\n",
      "DEBUG: imputing column property_damage type: <class 'str'>\n",
      "DEBUG: imputing column police_report_available type: <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhail/Downloads/code/0. Resources - insuranceFraudDetection/insuranceFraudDetection/code/fraudDetection/data_preprocessing/preprocessing.py:115: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[column] = data[column].replace({'Y': 1, 'N': 0, 'YES': 1, 'NO': 0, 'Yes': 1, 'No': 0, 'yes': 1, 'no': 0})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "\n",
    "# Import your Preprocessor class\n",
    "from data_preprocessing import preprocessing\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "TRAINING_CSV = 'insuranceFraud.csv'  # <-- Change this to your actual training file\n",
    "MODEL_DIR = 'models'\n",
    "KMEANS_DIR = os.path.join(MODEL_DIR, 'KMeans')\n",
    "N_CLUSTERS = 3  # <-- Set this to the number of clusters you want\n",
    "\n",
    "# === STEP 1: Load and Preprocess Data ===\n",
    "print(\"Loading data...\")\n",
    "data = pd.read_csv(TRAINING_CSV)\n",
    "\n",
    "# Drop label and unnecessary columns (same as in prediction)\n",
    "drop_cols = [\n",
    "    'fraud_reported', 'policy_number','policy_bind_date','policy_state','insured_zip','incident_location',\n",
    "    'incident_date','incident_state','incident_city','insured_hobbies','auto_make',\n",
    "    'auto_model','auto_year','age','total_claim_amount'\n",
    "]\n",
    "data = data.drop([col for col in drop_cols if col in data.columns], axis=1)\n",
    "\n",
    "# Replace '?' with np.nan\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = preprocessing.Preprocessor(None, None)\n",
    "is_null_present, cols_with_missing_values = preprocessor.is_null_present(data)\n",
    "if is_null_present:\n",
    "    data = preprocessor.impute_missing_values(data, cols_with_missing_values)\n",
    "\n",
    "# Map policy_csl to numeric codes\n",
    "if 'policy_csl' in data.columns:\n",
    "    csl_map = {val: idx+1 for idx, val in enumerate(data['policy_csl'].unique())}\n",
    "    print(\"policy_csl mapping:\", csl_map)\n",
    "    data['policy_csl'] = data['policy_csl'].map(csl_map)\n",
    "\n",
    "# Encode all categorical columns\n",
    "data = preprocessor.encode_categorical_columns(data)\n",
    "\n",
    "# Drop columns with NaN if needed (optional, or set a threshold)\n",
    "data = data.dropna(axis=1)\n",
    "\n",
    "# Drop rows with NaN if any remain\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Scale numerical columns\n",
    "data = preprocessor.scale_numerical_columns(data)\n",
    "\n",
    "print(\"Final data shape for KMeans:\", data.shape)\n",
    "print(\"Sample data for KMeans:\\n\", data.head())\n",
    "\n",
    "# === STEP 2: Train KMeans ===\n",
    "print(\"Training KMeans...\")\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42)\n",
    "kmeans.fit(data)\n",
    "\n",
    "# === STEP 3: Save the KMeans Model ===\n",
    "# Create KMeans directory if it doesn't exist\n",
    "os.makedirs(KMEANS_DIR, exist_ok=True)\n",
    "\n",
    "# Save the KMeans model\n",
    "kmeans_path = os.path.join(KMEANS_DIR, 'KMeans.sav')\n",
    "with open(kmeans_path, 'wb') as f:\n",
    "    pickle.dump(kmeans, f)\n",
    "\n",
    "print(f\"KMeans model saved to {kmeans_path}\")\n",
    "\n",
    "# === STEP 4: Save cluster-specific models ===\n",
    "# For each cluster, save a separate model file\n",
    "for cluster in range(N_CLUSTERS):\n",
    "    cluster_dir = os.path.join(KMEANS_DIR, f'cluster_{cluster}')\n",
    "    os.makedirs(cluster_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the same KMeans model for each cluster\n",
    "    cluster_path = os.path.join(cluster_dir, 'model.sav')\n",
    "    with open(cluster_path, 'wb') as f:\n",
    "        pickle.dump(kmeans, f)\n",
    "    \n",
    "    print(f\"Saved model for cluster {cluster} at {cluster_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54852638-7af2-4c6d-8ca3-cf4d2a6d867d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
